scalar Long
scalar JSON

# Data format specification for MQTT message payloads
# Determines how payload data is interpreted and processed by the GraphQL API
enum DataFormat {
    # JSON format: payload is parsed as JSON and returned as structured data
    # Allows for rich querying and manipulation of message content
    # Invalid JSON will result in parsing errors
    JSON
    # Binary format: payload is treated as raw binary data encoded in base64
    # Preserves exact byte content for non-text data (images, files, etc.)
    # Always safe for any payload content regardless of encoding
    BINARY
}

enum MessageStoreType {
    NONE
    MEMORY
    HAZELCAST
    POSTGRES
    CRATEDB
    MONGODB
    SQLITE
}

enum MessageArchiveType {
    NONE
    POSTGRES
    CRATEDB
    MONGODB
    KAFKA
    SQLITE
}

# Metrics for the broker
type BrokerMetrics {
    # Total messages received from clients on this node
    messagesIn: Long!
    # Total messages sent to clients on this node
    messagesOut: Long!
    # Number of sessions on this node
    nodeSessionCount: Int!
    # Total number of sessions in the cluster
    clusterSessionCount: Int!
    # Total number of queued messages in the cluster
    queuedMessagesCount: Long!
    # Size of the topic index (TopicTree)
    topicIndexSize: Int!
    # Size of the client-to-node mapping
    clientNodeMappingSize: Int!
    # Total size of topic-to-node mapping sets
    topicNodeMappingSize: Int!
    # Messages received from other nodes via message bus
    messageBusIn: Long!
    # Messages sent to other nodes via message bus
    messageBusOut: Long!
    # ISO 8601 timestamp when these metrics were captured (e.g., "2024-01-15T10:30:00Z")
    timestamp: String!
}

# Represents a broker node in the MonsterMQ cluster
# Each broker node runs independently and can handle MQTT clients, message processing, and data storage
type Broker {
    # Unique identifier for this cluster node (used for load balancing and device assignment)
    nodeId: String!
    # Current performance metrics for this broker node (latest snapshot)
    # Returns array with single most recent metrics entry for consistency with metricsHistory
    metrics: [BrokerMetrics!]!
    # Historical performance metrics over a specified time range
    # Useful for monitoring trends, performance analysis, and capacity planning
    metricsHistory(
        # ISO 8601 start timestamp (optional - defaults to 24 hours ago)
        from: String
        # ISO 8601 end timestamp (optional - defaults to now)
        to: String
        # Alternative time range: metrics from the last N minutes (overrides from/to if specified)
        lastMinutes: Int
    ): [BrokerMetrics!]!
    # MQTT client sessions managed by this broker node
    # Sessions persist client state, subscriptions, and queued messages
    sessions(
        # Filter by session persistence type: true=clean, false=persistent, null=all
        cleanSession: Boolean,
        # Filter by connection status: true=active connections, false=disconnected, null=all
        connected: Boolean
    ): [Session!]!
}

# Represents a client session
type Session {
    # The client ID
    clientId: String!
    # The ID of the node this session is connected to
    nodeId: String!
    # Current metrics for this session (single most recent entry)
    metrics: [SessionMetrics!]!
    # Historical metrics data for this session
    metricsHistory(
        # ISO 8601 timestamp for start of time range (e.g., "2024-01-15T10:00:00Z")
        from: String
        # ISO 8601 timestamp for end of time range (e.g., "2024-01-15T11:00:00Z")
        to: String
        # Alternative to from/to: get metrics from the last N minutes
        lastMinutes: Int
    ): [SessionMetrics!]!
    # The subscriptions for this session
    subscriptions: [MqttSubscription!]!
    # Is the session clean
    cleanSession: Boolean!
    # The session expiry interval
    sessionExpiryInterval: Long!
    # The client's address
    clientAddress: String
    # Whether the client is currently connected
    connected: Boolean!
    # Number of queued messages for this session
    queuedMessageCount: Long!
}

# Metrics for a single session
type SessionMetrics {
    # Messages received from this client
    messagesIn: Long!
    # Messages sent to this client
    messagesOut: Long!
    # ISO 8601 timestamp when these metrics were captured (e.g., "2024-01-15T10:30:00Z")
    timestamp: String!
}

# Represents an MQTT subscription
type MqttSubscription {
    # The topic filter
    topicFilter: String!
    # The Quality of Service level
    qos: Int!
}

type Query {
    # Get the most recent value for a specific MQTT topic from the LastValueStore
    # Returns the latest published value with timestamp and QoS information
    # Useful for dashboard displays and current status monitoring
    currentValue(
        # Exact MQTT topic name (no wildcards allowed)
        topic: String!,
        # Data format for the payload: JSON (parsed) or BINARY (base64 encoded)
        format: DataFormat = JSON,
        # ArchiveGroup containing the topic's last value store
        archiveGroup: String = "Default"
    ): TopicValue

    # Get current values for multiple topics matching an MQTT topic filter
    # Supports MQTT wildcards: '+' (single level) and '#' (multi-level)
    # Returns array of most recent values from the LastValueStore
    currentValues(
        # MQTT topic filter with wildcards: "sensor/+/temperature", "device/#", etc.
        topicFilter: String!,
        # Data format for all returned payloads
        format: DataFormat = JSON,
        # Maximum number of topics to return (ordered by topic name)
        limit: Int = 100,
        # ArchiveGroup to search within
        archiveGroup: String = "Default"
    ): [TopicValue!]!

    # Get retained message for a specific MQTT topic from the RetainedMessageStore
    # Retained messages persist until explicitly removed or overwritten
    # Different from currentValue as it only includes messages published with retain=true
    retainedMessage(
        # Exact MQTT topic name
        topic: String!,
        # Data format for the payload
        format: DataFormat = JSON
    ): RetainedMessage

    # Get all retained messages matching an MQTT topic filter
    # Returns messages that were published with the MQTT retain flag
    # Useful for discovering what retained data exists in the system
    retainedMessages(
        # MQTT topic filter with wildcards (optional - null returns all retained messages)
        topicFilter: String,
        # Data format for all payloads
        format: DataFormat = JSON,
        # Maximum number of messages to return
        limit: Int = 100
    ): [RetainedMessage!]!

    # Query historical messages from the message archive
    # Searches through time-series data stored for long-term analysis
    # Returns messages within specified time range and topic filter
    archivedMessages(
        # MQTT topic filter with wildcards to match archived messages
        topicFilter: String!
        # ISO 8601 start timestamp: "2024-01-15T10:00:00Z" (optional - defaults to 24h ago)
        startTime: String
        # ISO 8601 end timestamp: "2024-01-15T11:00:00Z" (optional - defaults to now)
        endTime: String
        # Data format for all payloads
        format: DataFormat = JSON
        # Maximum number of messages to return (ordered by timestamp)
        limit: Int = 100
        # ArchiveGroup containing the message archive to search
        archiveGroup: String = "Default"
    ): [ArchivedMessage!]!
    
    # Search for topics by name pattern using SQL LIKE wildcards
    # Supports '%' (matches any sequence of characters) and '_' (matches single character)
    # Examples:
    #   pattern: "sensor%" → finds all topics starting with "sensor"
    #   pattern: "%temperature%" → finds all topics containing "temperature"
    #   pattern: "device_0_" → finds topics like "device_01", "device_02", etc.
    # Requires an ArchiveGroup to search within its last value store
    searchTopics(
        # SQL LIKE pattern with % and _ wildcards
        pattern: String!
        # Maximum number of topics to return
        limit: Int = 100
        # ArchiveGroup name to search within (each group has its own last value store)
        archiveGroup: String = "Default"
    ): [String!]!

    # Browse topics hierarchically using MQTT-style topic structure
    # Uses MQTT topic conventions: '/' as level separator, '+' for single-level wildcard
    # Returns only direct child topics (one level down) from the specified path
    # Examples:
    #   topic: "opcua" → returns ["opcua/device1", "opcua/device2"] (not deeper levels)
    #   topic: "opcua/+" → returns all topics at opcua/device level like "opcua/device1/sensor1"
    #   topic: "+" → returns all top-level topic categories
    # Requires an ArchiveGroup because topics are stored in the group's last value store
    browseTopics(
        # MQTT topic path with optional '+' single-level wildcard
        topic: String!
        # ArchiveGroup name containing the topics (required for data isolation)
        archiveGroup: String = "Default"
    ): [Topic!]!
    
    # Get broker node information and metrics for monitoring cluster health
    # Returns current metrics, session counts, and node status information
    broker(
        # Cluster node ID (optional - if omitted, returns current node)
        nodeId: String
    ): Broker

    # Get information about all broker nodes in the MonsterMQ cluster
    # Useful for cluster monitoring and load distribution analysis
    # Returns array of all active cluster nodes with their metrics
    brokers: [Broker!]!

    # Get MQTT client sessions across the cluster or from specific nodes
    # Sessions represent MQTT client connections with their state and subscriptions
    sessions(
        # Filter by specific cluster node (optional - if omitted, returns sessions from all nodes)
        nodeId: String,
        # Filter by session type: true=clean sessions, false=persistent sessions, null=all
        cleanSession: Boolean,
        # Filter by connection status: true=connected, false=disconnected, null=all
        connected: Boolean
    ): [Session!]!

    # Get detailed information about a specific MQTT client session
    # Includes metrics, subscriptions, and connection status
    session(
        # MQTT client ID to look up
        clientId: String!,
        # Node ID where session is located (optional - will be auto-discovered if omitted)
        nodeId: String
    ): Session

    # User Management - Get user accounts and their permissions
    # Returns authentication and authorization information for MQTT access control
    users(
        # Filter by specific username (optional - if omitted, returns all users)
        username: String
    ): [UserInfo!]!

    # ArchiveGroup Management - Get data archiving configurations
    # Shows how MQTT topics are organized and stored across different databases
    archiveGroups: [ArchiveGroupInfo!]!

    # Get detailed information about a specific ArchiveGroup
    # Includes topic filters, storage configuration, and connection status
    archiveGroup(
        # Name of the ArchiveGroup to retrieve
        name: String!
    ): ArchiveGroupInfo
}

type Mutation {
    # Authenticate with username/password to obtain a JWT token for API access
    # Required for accessing protected mutations (publishing, user management, etc.)
    # Returns null when user authentication is disabled in MonsterMQ configuration
    login(
        # Username for authentication
        username: String!,
        # Password for authentication
        password: String!
    ): LoginResult

    # Publish an MQTT message to a specific topic through the broker
    # Message will be distributed to all subscribers and optionally stored based on ArchiveGroup settings
    # Requires valid JWT token and publish permission for the topic
    publish(
        # Message details including topic, payload, QoS, and retention settings
        input: PublishInput!
    ): PublishResult!

    # Publish multiple MQTT messages in a single atomic operation
    # Useful for bulk data ingestion and reducing API call overhead
    # All messages must pass ACL checks or the entire batch will be rejected
    publishBatch(
        # Array of messages to publish simultaneously
        inputs: [PublishInput!]!
    ): [PublishResult!]!

    # Create a new user account with specified permissions and access rights
    # Sets up authentication credentials and initial ACL permissions
    # Requires admin JWT token for execution
    createUser(
        # User account details including username, password, and permission flags
        input: CreateUserInput!
    ): UserManagementResult!

    # Update an existing user account's permissions and settings
    # Can modify enabled status, subscription/publish rights, and admin privileges
    # Cannot change username or password (use setPassword for password changes)
    updateUser(
        # Updated user details (only specified fields will be changed)
        input: UpdateUserInput!
    ): UserManagementResult!

    # Permanently delete a user account and all associated ACL rules
    # This action cannot be undone - the user will immediately lose access
    # Active sessions for the user will be terminated
    deleteUser(
        # Username of the account to delete
        username: String!
    ): UserManagementResult!

    # Change the password for an existing user account
    # New password will be securely hashed before storage
    # User's existing sessions may need to re-authenticate
    setPassword(
        # Username and new password details
        input: SetPasswordInput!
    ): UserManagementResult!

    # Create a new ACL (Access Control List) rule for topic-level permissions
    # Rules define which topics a user can subscribe to or publish on
    # Higher priority rules override lower priority ones
    createAclRule(
        # ACL rule details including user, topic pattern, and permissions
        input: CreateAclRuleInput!
    ): UserManagementResult!

    # Update an existing ACL rule's permissions or topic pattern
    # Changes take effect immediately for new client connections
    # Existing subscriptions may be affected based on the changes
    updateAclRule(
        # Updated ACL rule details (ID required, other fields optional)
        input: UpdateAclRuleInput!
    ): UserManagementResult!

    # Delete an ACL rule permanently
    # Users may lose access to topics if this was their only permission rule
    # Active subscriptions using this rule may be terminated
    deleteAclRule(
        # Unique ID of the ACL rule to delete
        id: String!
    ): UserManagementResult!

    # Remove queued messages from persistent sessions to free up memory
    # Useful for clearing message backlogs from disconnected clients
    # Can target a specific client or purge all queued messages cluster-wide
    purgeQueuedMessages(
        # Client ID to purge messages for (optional - if omitted, purges all clients)
        clientId: String
    ): PurgeResult!

    # Create a new ArchiveGroup for organizing topic data storage
    # Defines which topics are stored, which databases to use, and retention policies
    # The group becomes active immediately and starts archiving matching topics
    createArchiveGroup(
        # ArchiveGroup configuration including topic filters and storage settings
        input: CreateArchiveGroupInput!
    ): ArchiveGroupResult!

    # Update an existing ArchiveGroup's configuration
    # Changes to topic filters take effect immediately
    # Database changes may require redeployment of the archive handlers
    updateArchiveGroup(
        # Updated ArchiveGroup settings (name required, other fields optional)
        input: UpdateArchiveGroupInput!
    ): ArchiveGroupResult!

    # Permanently delete an ArchiveGroup and stop archiving its topics
    # Existing archived data is preserved but no new data will be stored
    # Cannot delete the "Default" ArchiveGroup as it's required by the system
    deleteArchiveGroup(
        # Name of the ArchiveGroup to delete
        name: String!
    ): ArchiveGroupResult!

    # Enable a disabled ArchiveGroup to resume topic archiving
    # Restarts data collection for the group's topic filters
    # Useful for temporarily pausing and resuming data archiving
    enableArchiveGroup(
        # Name of the ArchiveGroup to enable
        name: String!
    ): ArchiveGroupResult!

    # Disable an ArchiveGroup to pause topic archiving without deleting it
    # Stops new data collection but preserves existing archived data
    # Configuration remains intact for future re-enabling
    disableArchiveGroup(
        # Name of the ArchiveGroup to disable
        name: String!
    ): ArchiveGroupResult!
}

type Subscription {
    # Subscribe to real-time MQTT message updates for topics matching a filter
    # Creates a persistent GraphQL subscription that streams live data as messages are published
    # Uses WebSocket connection to deliver low-latency updates to dashboards and monitoring tools
    # Subscription will remain active until client disconnects or unsubscribes
    topicUpdates(
        # MQTT topic filter with wildcards: "sensor/+/temperature", "device/#", etc.
        # Supports both single-level (+) and multi-level (#) MQTT wildcards
        topicFilter: String!,
        # Data format for streamed message payloads
        format: DataFormat = JSON
    ): TopicUpdate!

    # Subscribe to real-time updates from multiple topic filters simultaneously
    # Efficient way to monitor different topic categories in a single subscription
    # All matching messages from any of the specified filters will be streamed
    # Useful for comprehensive dashboard monitoring across topic hierarchies
    multiTopicUpdates(
        # Array of MQTT topic filters to monitor simultaneously
        # Each filter supports MQTT wildcards independently
        topicFilters: [String!]!,
        # Data format for all streamed message payloads
        format: DataFormat = JSON
    ): TopicUpdate!
}

input PublishInput {
    # MQTT topic to publish the message to (no wildcards allowed for publishing)
    # Must follow MQTT topic naming conventions: use '/' as level separator
    topic: String!
    # Message payload content - format depends on the 'format' field
    # For JSON format: valid JSON string, for BINARY format: base64 encoded data
    payload: String!
    # Specifies how the payload should be interpreted and processed
    # JSON: payload is parsed as JSON, BINARY: payload is treated as base64 encoded binary data
    format: DataFormat = JSON
    # MQTT Quality of Service level: 0 (at most once), 1 (at least once), 2 (exactly once)
    # Higher QoS levels provide stronger delivery guarantees but with increased overhead
    qos: Int = 0
    # Whether this message should be retained by the broker for future subscribers
    # Retained messages are delivered to clients that subscribe after publication
    retained: Boolean = false
}

type PublishResult {
    success: Boolean!
    topic: String!
    timestamp: Long!
    error: String
}

type TopicValue {
    topic: String!
    payload: String!
    format: DataFormat!
    timestamp: Long!
    qos: Int!
}

type Topic {
    # The topic name
    name: String!
    # The current value for this topic (null if no value exists)
    value(format: DataFormat = JSON): TopicValue
}

type RetainedMessage {
    topic: String!
    payload: String!
    format: DataFormat!
    timestamp: Long!
    qos: Int!
}

type ArchivedMessage {
    topic: String!
    payload: String!
    format: DataFormat!
    timestamp: Long!
    qos: Int!
    clientId: String
}

type TopicUpdate {
    topic: String!
    payload: String!
    format: DataFormat!
    timestamp: Long!
    qos: Int!
    retained: Boolean!
    clientId: String
}

# User Management Types

type UserInfo {
    username: String!
    enabled: Boolean!
    canSubscribe: Boolean!
    canPublish: Boolean!
    isAdmin: Boolean!
    createdAt: String
    updatedAt: String
    aclRules: [AclRuleInfo!]!
}

type AclRuleInfo {
    id: String!
    username: String!
    topicPattern: String!
    canSubscribe: Boolean!
    canPublish: Boolean!
    priority: Int!
    createdAt: String
}

input CreateUserInput {
    username: String!
    password: String!
    enabled: Boolean = true
    canSubscribe: Boolean = true
    canPublish: Boolean = true
    isAdmin: Boolean = false
}

input UpdateUserInput {
    username: String!
    enabled: Boolean
    canSubscribe: Boolean
    canPublish: Boolean
    isAdmin: Boolean
}

input SetPasswordInput {
    username: String!
    password: String!
}

input CreateAclRuleInput {
    username: String!
    topicPattern: String!
    canSubscribe: Boolean = false
    canPublish: Boolean = false
    priority: Int = 0
}

input UpdateAclRuleInput {
    id: String!
    username: String
    topicPattern: String
    canSubscribe: Boolean
    canPublish: Boolean
    priority: Int
}

# ArchiveGroup Management Types
#
# ArchiveGroups are essential for organizing and managing MQTT data storage in MonsterMQ.
# Each ArchiveGroup defines:
# 1. Topic filters that determine which MQTT topics are stored
# 2. Storage backends (PostgreSQL, CrateDB, MongoDB, etc.) for both last values and historical data
# 3. Data retention policies and purge intervals
# 4. Whether to store only retained messages or all messages matching the filters
#
# Why ArchiveGroups are required for searchTopics and browseTopics:
# - MonsterMQ stores topic data in separate databases/collections per ArchiveGroup
# - Each group has its own "last value store" containing the most recent value for each topic
# - This isolation allows different topic categories to use different storage backends
# - Examples: IoT sensors in PostgreSQL, OPC UA data in CrateDB, logs in MongoDB
# - The "Default" ArchiveGroup is required and typically contains general MQTT topics
#
# Topic organization example:
# - Default ArchiveGroup: general/* topics → PostgreSQL
# - Industrial ArchiveGroup: opcua/*, modbus/* → CrateDB
# - Logging ArchiveGroup: logs/*, events/* → MongoDB

type NodeConnectionStatus {
    nodeId: String!
    # Connection status for different store components
    messageArchive: Boolean
    lastValueStore: Boolean
    # Error message if connection failed
    error: String
    # Timestamp when status was checked
    timestamp: Long!
}

type ArchiveGroupInfo {
    name: String!
    enabled: Boolean!
    deployed: Boolean!
    deploymentId: String
    topicFilter: [String!]!
    retainedOnly: Boolean!
    lastValType: MessageStoreType!
    archiveType: MessageArchiveType!
    lastValRetention: String
    archiveRetention: String
    purgeInterval: String
    createdAt: String
    updatedAt: String
    # Database connection status from all nodes in the cluster
    connectionStatus: [NodeConnectionStatus!]!
}

input CreateArchiveGroupInput {
    name: String!
    topicFilter: [String!]!
    retainedOnly: Boolean = false
    lastValType: MessageStoreType!
    archiveType: MessageArchiveType!
    lastValRetention: String
    archiveRetention: String
    purgeInterval: String
}

input UpdateArchiveGroupInput {
    name: String!
    topicFilter: [String!]
    retainedOnly: Boolean
    lastValType: MessageStoreType
    archiveType: MessageArchiveType
    lastValRetention: String
    archiveRetention: String
    purgeInterval: String
}

type ArchiveGroupResult {
    success: Boolean!
    message: String
    archiveGroup: ArchiveGroupInfo
}

# Authentication Types
type LoginResult {
    success: Boolean!
    token: String
    message: String
    username: String
    isAdmin: Boolean!
}

type UserManagementResult {
    success: Boolean!
    message: String
    user: UserInfo
    aclRule: AclRuleInfo
}

type PurgeResult {
    success: Boolean!
    message: String
    deletedCount: Long!
}

# OPC UA Device Configuration Types

enum OpcUaPublishMode {
    SINGLE
    SEPARATE
}

# Certificate configuration for OPC UA connections with TLS/SSL security
type CertificateConfig {
    # Directory for storing certificates and keystores (relative to application root)
    securityDir: String!
    # Application name used in certificate subject (e.g., "MonsterMQ@localhost")
    applicationName: String!
    # Unique application URI for OPC UA client identification
    applicationUri: String!
    # Organization name for certificate subject
    organization: String!
    # Organizational unit for certificate subject  
    organizationalUnit: String!
    # Locality/city name for certificate subject
    localityName: String!
    # Two-letter country code for certificate subject (e.g., "US", "DE")
    countryCode: String!
    # Whether to automatically create self-signed certificates if none exist
    createSelfSigned: Boolean!
    # Password for protecting the keystore containing client certificates
    keystorePassword: String!
    # Whether to validate server certificates (enable for production security)
    validateServerCertificate: Boolean!
    # Auto-accept and save new server certificates to trust store (useful for initial setup)
    autoAcceptServerCertificates: Boolean!
}

# OPC UA address configuration for subscribing to OPC UA server nodes
type OpcUaAddress {
    # OPC UA node address - can be either NodeId or BrowsePath format:
    # NodeId examples: "ns=2;i=1234", "ns=2;s=MyDevice.Temperature", "ns=2;g=550e8400-e29b-41d4-a716-446655440000"
    # BrowsePath examples: "/Root/Objects/MyDevice/Temperature", "/Objects/2:MyDevice/2:Sensor1"
    # NodeId is more efficient, BrowsePath is more human-readable but requires browsing
    address: String!
    # MQTT topic where OPC UA values will be published
    topic: String!
    # How to publish OPC UA values: SINGLE (all in one message) or SEPARATE (individual messages)
    publishMode: OpcUaPublishMode!
    # Whether to remove the browse path from the topic name when using BrowsePath addresses
    removePath: Boolean!
}

type MonitoringParameters {
    bufferSize: Int!
    samplingInterval: Float!
    discardOldest: Boolean!
}

enum SecurityPolicy {
    None
    Basic256Sha256
    Basic256
    Basic128Rsa15
    Aes256_Sha256_RsaPss
    Aes128_Sha256_RsaOaep
}

type OpcUaConnectionConfig {
    endpointUrl: String!
    updateEndpointUrl: Boolean!
    securityPolicy: SecurityPolicy!
    username: String
    password: String
    subscriptionSamplingInterval: Float!
    keepAliveFailuresAllowed: Int!
    reconnectDelay: Long!
    connectionTimeout: Long!
    requestTimeout: Long!
    monitoringParameters: MonitoringParameters!
    addresses: [OpcUaAddress!]!
    # Certificate configuration for TLS/SSL connections and client authentication
    certificateConfig: CertificateConfig!
}

type OpcUaDevice {
    name: String!
    namespace: String!
    nodeId: String!
    backupNodeId: String
    config: OpcUaConnectionConfig!
    enabled: Boolean!
    type: String!
    createdAt: String!
    updatedAt: String!
    isOnCurrentNode: Boolean!
}

type ClusterNode {
    nodeId: String!
    isCurrent: Boolean!
}

type OpcUaDeviceResult {
    success: Boolean!
    device: OpcUaDevice
    errors: [String!]!
}


input MonitoringParametersInput {
    bufferSize: Int = 100
    samplingInterval: Float = 0.0
    discardOldest: Boolean = false
}

# Input type for certificate configuration settings
input CertificateConfigInput {
    # Directory for storing certificates and keystores (default: "security")
    securityDir: String = "security"
    # Application name for certificate subject (default: "MonsterMQ@localhost")
    applicationName: String = "MonsterMQ@localhost"
    # Application URI for OPC UA client identification (default: "urn:MonsterMQ:Client")
    applicationUri: String = "urn:MonsterMQ:Client"
    # Organization name for certificate subject (default: "MonsterMQ")
    organization: String = "MonsterMQ"
    # Organizational unit for certificate subject (default: "Client")
    organizationalUnit: String = "Client"
    # Locality/city name for certificate subject (default: "Unknown")
    localityName: String = "Unknown"
    # Two-letter country code (default: "XX")
    countryCode: String = "XX"
    # Whether to create self-signed certificates automatically (default: true)
    createSelfSigned: Boolean = true
    # Keystore password for certificate protection (default: "password")
    keystorePassword: String = "password"
    # Whether to validate server certificates (default: true for security)
    validateServerCertificate: Boolean = true
    # Auto-accept and save new server certificates (default: false, enable for initial setup)
    autoAcceptServerCertificates: Boolean = false
}

input OpcUaConnectionConfigInput {
    endpointUrl: String!
    updateEndpointUrl: Boolean = true
    securityPolicy: SecurityPolicy = None
    username: String
    password: String
    subscriptionSamplingInterval: Float = 0.0
    keepAliveFailuresAllowed: Int = 3
    reconnectDelay: Long = 5000
    connectionTimeout: Long = 10000
    requestTimeout: Long = 5000
    monitoringParameters: MonitoringParametersInput
    # Certificate configuration for TLS/SSL and client authentication
    certificateConfig: CertificateConfigInput
}

input OpcUaAddressInput {
    # OPC UA node address - supports two formats:
    # 1. NodeId (recommended for performance): "ns=2;i=1234", "ns=2;s=MyDevice.Temperature", "ns=2;g=UUID"
    # 2. BrowsePath (human-readable): "/Root/Objects/MyDevice/Temperature", "/Objects/2:MyDevice/2:Sensor1"
    address: String!
    # MQTT topic where OPC UA values will be published
    topic: String!
    # SINGLE: publish all subscribed values in one JSON object, SEPARATE: individual messages per value
    publishMode: OpcUaPublishMode = SEPARATE
    # For BrowsePath addresses: whether to remove the path prefix from generated topic names
    removePath: Boolean = true
}

input OpcUaDeviceInput {
    name: String!
    namespace: String!
    nodeId: String!
    backupNodeId: String
    config: OpcUaConnectionConfigInput!
    enabled: Boolean = true
    type: String = "OPC Client"
}

# Extend existing Query type
extend type Query {
    # Get all OPC UA device configurations across the entire cluster
    # Returns devices from all cluster nodes, showing their assignment and status
    opcUaDevices: [OpcUaDevice!]!

    # Get a specific OPC UA device configuration by its unique name
    # Device names must be unique across the entire MonsterMQ cluster
    opcUaDevice(name: String!): OpcUaDevice

    # Get OPC UA devices assigned to a specific cluster node
    # Useful for monitoring device distribution and cluster load balancing
    opcUaDevicesByNode(nodeId: String!): [OpcUaDevice!]!

    # Get list of all available cluster nodes for device assignment
    # Shows which nodes are available for deploying OPC UA device connectors
    clusterNodes: [ClusterNode!]!
}

# Extend existing Mutation type
extend type Mutation {
    # Add a new OPC UA device configuration to the cluster
    # Creates a device connector that will be deployed on the specified cluster node
    # The device will automatically start collecting data from the configured OPC UA addresses
    addOpcUaDevice(input: OpcUaDeviceInput!): OpcUaDeviceResult!

    # Update an existing OPC UA device configuration
    # Changes take effect immediately - the device connector will be redeployed with new settings
    # Useful for modifying connection parameters, security settings, or sampling intervals
    updateOpcUaDevice(name: String!, input: OpcUaDeviceInput!): OpcUaDeviceResult!

    # Delete an OPC UA device configuration permanently
    # Stops the device connector and removes all configuration data
    # Returns true if deletion was successful, false if device was not found
    deleteOpcUaDevice(name: String!): Boolean!

    # Enable or disable an OPC UA device without deleting its configuration
    # Disabled devices stop collecting data but retain their configuration
    # Useful for temporarily pausing data collection or troubleshooting
    toggleOpcUaDevice(name: String!, enabled: Boolean!): OpcUaDeviceResult!

    # Reassign an OPC UA device to a different cluster node
    # Moves the device connector from one node to another for load balancing
    # The device configuration remains unchanged, only the deployment location changes
    reassignOpcUaDevice(name: String!, nodeId: String!): OpcUaDeviceResult!

    # Add a new OPC UA address (node subscription) to an existing device
    # The address can be either a NodeId or BrowsePath - see OpcUaAddressInput for format details
    # New addresses will immediately start collecting data from the OPC UA server
    addOpcUaAddress(deviceName: String!, input: OpcUaAddressInput!): OpcUaDeviceResult!

    # Remove an OPC UA address subscription from a device
    # Stops data collection for the specified address while keeping other addresses active
    # Use the exact address string that was used when adding the address
    deleteOpcUaAddress(deviceName: String!, address: String!): OpcUaDeviceResult!
}