# MonsterMQ Configuration - Kafka Streaming Integration
# This configuration demonstrates streaming MQTT messages to Apache Kafka
# Use cases: Event sourcing, data pipelines, analytics, microservices integration

# Network Configuration
TCP: 1883
WS: 8080
TCPS: 0     # Disabled for this example
WSS: 0      # Disabled for this example
MaxMessageSizeKb: 512

# Storage Configuration
SessionStoreType: POSTGRES      # Persistent sessions
RetainedStoreType: POSTGRES     # Persistent retained messages
ConfigStoreType: POSTGRES
QueuedMessagesEnabled: true     # Enable QoS message queuing

# PostgreSQL Configuration (for sessions and retained messages)
Postgres:
  Url: jdbc:postgresql://localhost:5432/monster
  User: system
  Pass: manager

# Kafka Configuration
Kafka:
  # Required: Kafka broker addresses (comma-separated for multiple brokers)
  Servers: localhost:9092
  # Alternative for multiple brokers:
  # Servers: kafka1:9092,kafka2:9092,kafka3:9092

  # Optional: Kafka client configuration (applies to all producers and consumers)
  # All standard Kafka properties are supported
  Config:
    # Performance tuning
    compression.type: "snappy"        # Compress messages (none, gzip, snappy, lz4, zstd)
    batch.size: "32768"               # Batch size in bytes (32KB)
    linger.ms: "10"                   # Wait time for batching (milliseconds)

    # Reliability
    acks: "1"                         # Acknowledgment level (0, 1, all)
    retries: "3"                      # Number of retries on failure

    # Example: Security configuration (uncomment and configure as needed)
    # security.protocol: "SASL_SSL"
    # sasl.mechanism: "SCRAM-SHA-256"
    # sasl.jaas.config: |
    #   org.apache.kafka.common.security.scram.ScramLoginModule required
    #   username="myuser"
    #   password="mypassword";
    #
    # SSL/TLS configuration
    # ssl.truststore.location: "/path/to/truststore.jks"
    # ssl.truststore.password: "truststore-password"
    # ssl.keystore.location: "/path/to/keystore.jks"
    # ssl.keystore.password: "keystore-password"
    #
    # Connection tuning
    # request.timeout.ms: "30000"
    # connections.max.idle.ms: "540000"

  # Optional: Use Kafka as internal message bus between MonsterMQ nodes
  Bus:
    Enabled: false      # Set to true to use Kafka instead of Vert.x EventBus
    Topic: monster-bus  # Topic for internal MonsterMQ communication
   
# Optional: SparkplugB Extension
SparkplugMetricExpansion:
  Enabled: true    # Expand SparkplugB messages before streaming to Kafka

# MCP Server configuration
MCP:
  Enabled: true
  Port: 3000

# Usage Notes:
# 1. Start Kafka first:
#    docker-compose up -d kafka
#    
# 2. Create Kafka topics (optional, auto-created if enabled):
#    kafka-topics --create --topic sensors --bootstrap-server localhost:9092
#    kafka-topics --create --topic events --bootstrap-server localhost:9092
#    kafka-topics --create --topic datalake --bootstrap-server localhost:9092
#
# 3. Start MonsterMQ:
#    ./run.sh -config config-kafka.yaml
#
# 4. Consume from Kafka:
#    kafka-console-consumer --topic sensors --from-beginning --bootstrap-server localhost:9092
#
# Kafka Message Format:
# - Topic: The archive group name (sensors, events, datalake)
# - Key: MQTT topic name
# - Value: JSON with { topic, payload, timestamp, qos, retained, clientId }
#
# Integration Examples:
# - Apache Spark: Stream processing of sensor data
# - Apache Flink: Real-time analytics on event streams
# - Elasticsearch: Index all messages via Kafka Connect
# - Data Lake: Store raw messages in S3/HDFS via Kafka Connect
# - Microservices: React to MQTT events via Kafka consumers